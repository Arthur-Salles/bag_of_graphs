{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pyts \n",
    "import matplotlib.pyplot as plt\n",
    "import bag2graph\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 6, 100), (40,), (40, 6, 100), (40,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyts.datasets\n",
    "\n",
    "x_train, x_test, y_train, y_test = pyts.datasets.load_basic_motions(return_X_y=True)#fetch_ucr_dataset('Strawberry',use_cache=False,data_home=return_X_y=True)\n",
    "\n",
    "total_labels = np.unique(y_train)\n",
    "# print(total_labels)\n",
    "label_map = dict(zip(total_labels, range(len(total_labels))))\n",
    "\n",
    "temp_ytrain = []\n",
    "for t in y_train:\n",
    "    temp_ytrain.append(label_map[t])\n",
    "temp_ytest = []\n",
    "for t in y_test:\n",
    "    temp_ytest.append(label_map[t])\n",
    "\n",
    "y_test = np.array(temp_ytest)\n",
    "y_train = np.array(temp_ytrain)\n",
    "\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaa' 'aab' 'aac' 'aba' 'abb' 'abc' 'aca' 'acb' 'acc' 'baa' 'bab' 'bac'\n",
      " 'bba' 'bbb' 'bbc' 'bca' 'bcb' 'bcc' 'caa' 'cab' 'cac' 'cba' 'cbb' 'cbc'\n",
      " 'cca' 'ccb' 'ccc'] 27\n",
      "Filtered 10 top words : ['abb' 'ccb' 'aca' 'baa' 'acc' 'cba' 'cca' 'bba' 'cac' 'caa']\n"
     ]
    }
   ],
   "source": [
    "b2g = bag2graph.Bag2Graph(10, 3, 3)\n",
    "t = b2g.apply_bow_uni(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_exs = np.array([\n",
    "    ['cb', 'da', 'ac', 'ac', 'ab', 'ad', 'cd'],\n",
    "    ['cd', 'cb', 'ac', 'ad', 'cd', 'ac', 'cb'],\n",
    "    ['ab', 'da', 'ac', 'ab', 'ad', 'ac', 'ab'],\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cb' 'da' 'ac' 'ac' 'ab' 'ad' 'cd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur\\AppData\\Local\\Temp\\ipykernel_5328\\1984634718.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  n_adj = adj_m / row_sum[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan],\n",
       "       [5. , 0. , 2. , 1.5, 1.5, 0. , 0. ],\n",
       "       [0. , 0. , 3. , 0. , 0. , 7. , 0. ],\n",
       "       [nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequencia_test = t[0]\n",
    "sequencia_test = paper_exs[0]\n",
    "# print(sequencia_test)\n",
    "\n",
    "def get_word_neighbors(arr):\n",
    "    n = len(arr)\n",
    "    result = np.empty((n, 3), dtype=arr.dtype)\n",
    "\n",
    "    result[:, 1] = arr  \n",
    "    result[1:, 0] = arr[:-1]  \n",
    "    result[:-1, 2] = arr[1:]  \n",
    "\n",
    "    result[0, 0] = arr[-1] \n",
    "    result[-1, 2] = arr[0] \n",
    "\n",
    "    return result\n",
    "\n",
    "# print(triplets)\n",
    "\n",
    "def get_adj_matrix(arr, triplets, max_words):\n",
    "    # u_words = np.sort(np.unique(arr))\n",
    "    n = len(max_words)\n",
    "    # print(u_words)\n",
    "    d_word = dict(zip(max_words,range(n)))\n",
    "    # print(d_word)\n",
    "    adj_m = np.zeros((n, n))\n",
    "    # print(triplets)\n",
    "    \n",
    "    for (p_w, w, n_w) in triplets:\n",
    "        ipw , iw, inw = d_word[p_w], d_word[w], d_word[n_w]\n",
    "        adj_m[ipw, iw] += 1\n",
    "        adj_m[iw, inw] += 1\n",
    "\n",
    "    # print(adj_m, '\\n\\n',adj_m.T)\n",
    "    row_sum = np.sum(adj_m, axis=1)\n",
    "    # print(row_sum)\n",
    "    n_adj = adj_m / row_sum[:, np.newaxis]\n",
    "\n",
    "    # print(n_adj)\n",
    "    return n_adj\n",
    "\n",
    "    \n",
    "print(paper_exs[0])\n",
    "# triplets = get_word_neighbors(paper_exs[0])\n",
    "# n_adj = get_adj_matrix(paper_exs[0], triplets)\n",
    "\n",
    "\n",
    "# NAO TA FUNCIONANDO \n",
    "# PRA ARRUMAR E JUNTAR TODAS PALAVRAS\n",
    "# PEGAR O DICT MAXIMO DELAS SENDO A SOMA DE TODAS PALABRAS EXISTENTES \n",
    "# DPS PASSAR TUDO JUNTO \n",
    "\n",
    "\n",
    "paper_words = np.unique(paper_exs, axis=1)\n",
    "paper_words_size = paper_words.shape[-1] # precisa pegar o maior dps\n",
    "\n",
    "for i in range(3):\n",
    "    sequencia_test = paper_exs[i]\n",
    "    # print(sequencia_test)\n",
    "    triplets = get_word_neighbors(sequencia_test)\n",
    "    t += get_adj_matrix(sequencia_test, triplets, paper_words[0] )\n",
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
